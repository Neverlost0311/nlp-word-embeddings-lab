{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiaML8Tyoy2YE5dXgtoIsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neverlost0311/nlp-word-embeddings-lab/blob/main/04-sentiment-classification/lab4_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 4: Sentiment Classification with Embeddings\n",
        "\n",
        "## Objective\n",
        "In this lab, we will build a sentiment analysis system using **text embeddings** as features for a machine learning model.\n",
        "\n",
        "We will:\n",
        "- Load and preprocess the IMDB movie reviews dataset\n",
        "- Generate embeddings for reviews using a modern embedding model\n",
        "- Convert sentiment labels (positive/negative) into numeric form\n",
        "- Split the data into training and test sets\n",
        "- Train a classifier on top of embeddings\n",
        "- Evaluate the model using standard metrics\n",
        "- Build a prediction function for new reviews\n",
        "\n",
        "This lab demonstrates how **embeddings can be used as input features for classical machine learning models**.\n"
      ],
      "metadata": {
        "id": "Tb3Il2ZC4BZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 2: Install & Import Libraries\n",
        "# ================================\n",
        "\n",
        "# Install required libraries\n",
        "!pip install -q google-genai scikit-learn pandas numpy tqdm\n",
        "\n",
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Gemini client\n",
        "from google import genai\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ All libraries installed and imported successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxwWCTe44CCR",
        "outputId": "d6c7e00f-3c75-43f6-beeb-78d77bae4a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries installed and imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 3: Setup Gemini API Key\n",
        "# ================================\n",
        "\n",
        "# Enter your API key securely\n",
        "from getpass import getpass\n",
        "\n",
        "API_KEY = getpass(\"Enter your Gemini API Key: \")\n",
        "\n",
        "# Set environment variable\n",
        "os.environ[\"GEMINI_API_KEY\"] = API_KEY\n",
        "\n",
        "# Create Gemini client\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "print(\"‚úÖ API key loaded and Gemini client created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0EIhZOH4Jrq",
        "outputId": "0a3a5d17-59c2-4f7c-a403-63b548484fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Gemini API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API key loaded and Gemini client created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 4: Embedding Helper Functions\n",
        "# ================================\n",
        "\n",
        "MODEL_NAME = \"models/text-embedding-004\"\n",
        "\n",
        "def get_embeddings_batch(texts, batch_size=50):\n",
        "    \"\"\"\n",
        "    Generate embeddings for a list of texts using Gemini in batches.\n",
        "    Returns a numpy array of shape (len(texts), embedding_dim)\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        print(f\"Embedding batch {i} to {i+len(batch)-1}...\")\n",
        "\n",
        "        result = client.models.embed_content(\n",
        "            model=MODEL_NAME,\n",
        "            contents=batch\n",
        "        )\n",
        "\n",
        "        batch_embeddings = [e.values for e in result.embeddings]\n",
        "        all_embeddings.extend(batch_embeddings)\n",
        "\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "print(\"‚úÖ Embedding functions ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIe2aIKm4YFI",
        "outputId": "f5ed8137-d3b9-434a-9feb-2c046f9f5520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Embedding functions ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Find the zip file automatically\n",
        "zip_path = None\n",
        "for file in os.listdir(\".\"):\n",
        "    if file.endswith(\".zip\"):\n",
        "        zip_path = file\n",
        "        break\n",
        "\n",
        "if zip_path is None:\n",
        "    raise FileNotFoundError(\"‚ùå No ZIP file found in current directory.\")\n",
        "else:\n",
        "    print(\"‚úÖ Found ZIP file:\", zip_path)\n",
        "\n",
        "# Extract it\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")\n",
        "\n",
        "print(\"‚úÖ ZIP extracted successfully into ./dataset/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxaBQYKe6TUu",
        "outputId": "ec1631a9-4d57-40ff-f94c-043d42419f09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found ZIP file: 25bf82dd-b16e-4f0f-9ea2-eba1c8eb9828_Code-text_embeddings (1).zip\n",
            "‚úÖ ZIP extracted successfully into ./dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 6: Find and Load IMDB Dataset\n",
        "# ================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Search for IMDB Dataset CSV inside dataset folder\n",
        "imdb_path = None\n",
        "\n",
        "for root, dirs, files in os.walk(\"dataset\"):\n",
        "    for file in files:\n",
        "        if \"IMDB\" in file and file.endswith(\".csv\"):\n",
        "            imdb_path = os.path.join(root, file)\n",
        "            break\n",
        "\n",
        "if imdb_path is None:\n",
        "    raise FileNotFoundError(\"‚ùå Could not find IMDB Dataset CSV inside dataset folder.\")\n",
        "else:\n",
        "    print(\"‚úÖ Found IMDB dataset at:\")\n",
        "    print(imdb_path)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(imdb_path)\n",
        "\n",
        "print(\"\\n‚úÖ Dataset loaded successfully!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "# Show first 5 rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "zpzsVbwz6kAk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "cf7164bb-ae6d-45d9-d518-7e0a64f676ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found IMDB dataset at:\n",
            "dataset/Code/code - openai version/data/IMDB Dataset.csv\n",
            "\n",
            "‚úÖ Dataset loaded successfully!\n",
            "Shape: (50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00386f9c-c250-4b0b-88da-7fe310a74e74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00386f9c-c250-4b0b-88da-7fe310a74e74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00386f9c-c250-4b0b-88da-7fe310a74e74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00386f9c-c250-4b0b-88da-7fe310a74e74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 7: Prepare Dataset for Training\n",
        "# ================================\n",
        "\n",
        "# Map sentiment to numeric labels\n",
        "df[\"sentiment_label\"] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
        "\n",
        "# Shuffle dataset\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Take only 1000 samples to save API usage\n",
        "df_small = df.iloc[:1000]\n",
        "\n",
        "print(\"‚úÖ Using subset shape:\", df_small.shape)\n",
        "print(\"Sentiment distribution:\")\n",
        "print(df_small[\"sentiment_label\"].value_counts())\n",
        "\n",
        "# Extract texts and labels\n",
        "texts = df_small[\"review\"].tolist()\n",
        "labels = df_small[\"sentiment_label\"].tolist()\n",
        "\n",
        "# Show one example\n",
        "print(\"\\nüìù Sample review (first 500 chars):\\n\")\n",
        "print(texts[0][:500], \"...\")\n",
        "print(\"\\nLabel:\", labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv0Zyc5I-EpN",
        "outputId": "0c235232-9a06-496e-e961-2a9577bb8110"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using subset shape: (1000, 3)\n",
            "Sentiment distribution:\n",
            "sentiment_label\n",
            "0    524\n",
            "1    476\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìù Sample review (first 500 chars):\n",
            "\n",
            "I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Di ...\n",
            "\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 8: Generate Embeddings for Reviews\n",
        "# ================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"üöÄ Generating embeddings for\", len(texts), \"reviews...\")\n",
        "\n",
        "# Generate embeddings in batches\n",
        "X_embeddings = get_embeddings_batch(texts, batch_size=50)\n",
        "\n",
        "# Convert labels to numpy array\n",
        "y = np.array(labels)\n",
        "\n",
        "print(\"‚úÖ Embeddings generated!\")\n",
        "print(\"Embedding matrix shape:\", X_embeddings.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX8CUERP-bpb",
        "outputId": "cfc393b6-b6fc-448a-dce5-61aa1f843211"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Generating embeddings for 1000 reviews...\n",
            "Embedding batch 0 to 49...\n",
            "Embedding batch 50 to 99...\n",
            "Embedding batch 100 to 149...\n",
            "Embedding batch 150 to 199...\n",
            "Embedding batch 200 to 249...\n",
            "Embedding batch 250 to 299...\n",
            "Embedding batch 300 to 349...\n",
            "Embedding batch 350 to 399...\n",
            "Embedding batch 400 to 449...\n",
            "Embedding batch 450 to 499...\n",
            "Embedding batch 500 to 549...\n",
            "Embedding batch 550 to 599...\n",
            "Embedding batch 600 to 649...\n",
            "Embedding batch 650 to 699...\n",
            "Embedding batch 700 to 749...\n",
            "Embedding batch 750 to 799...\n",
            "Embedding batch 800 to 849...\n",
            "Embedding batch 850 to 899...\n",
            "Embedding batch 900 to 949...\n",
            "Embedding batch 950 to 999...\n",
            "‚úÖ Embeddings generated!\n",
            "Embedding matrix shape: (1000, 768)\n",
            "Labels shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 9: Train / Test Split\n",
        "# ================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_embeddings, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Train/Test split done!\")\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Test labels shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "608pQLPj-tX-",
        "outputId": "38637a38-b1f9-49cb-c615-d2d43773d1a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Train/Test split done!\n",
            "Training set shape: (800, 768)\n",
            "Test set shape: (200, 768)\n",
            "Training labels shape: (800,)\n",
            "Test labels shape: (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 10: Train XGBoost Classifier\n",
        "# ================================\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"üöÄ Training XGBoost classifier...\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Model training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-gWyJ5YHk6P",
        "outputId": "59af988c-c78a-4732-c246-0e1b6269b60c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Training XGBoost classifier...\n",
            "‚úÖ Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 11: Evaluate the Model\n",
        "# ================================\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"‚úÖ Test Accuracy:\", acc)\n",
        "\n",
        "# Detailed report\n",
        "print(\"\\nüìä Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVQsriD9H1e1",
        "outputId": "fa449248-8600-4067-f268-c0dc1053392d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Test Accuracy: 0.955\n",
            "\n",
            "üìä Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.96      0.96      0.96       114\n",
            "    Positive       0.95      0.94      0.95        86\n",
            "\n",
            "    accuracy                           0.95       200\n",
            "   macro avg       0.95      0.95      0.95       200\n",
            "weighted avg       0.95      0.95      0.95       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 12: Predict Sentiment for New Reviews\n",
        "# ================================\n",
        "\n",
        "def predict_sentiment(review_text):\n",
        "    # Generate embedding for the input text\n",
        "    embedding = get_embeddings_batch([review_text], batch_size=1)\n",
        "\n",
        "    # Predict using trained model\n",
        "    pred = model.predict(embedding)[0]\n",
        "    prob = model.predict_proba(embedding)[0]\n",
        "\n",
        "    label = \"Positive\" if pred == 1 else \"Negative\"\n",
        "\n",
        "    print(\"üìù Review:\")\n",
        "    print(review_text)\n",
        "    print(\"\\nüéØ Prediction:\", label)\n",
        "    print(\"üìä Confidence:\", prob)\n",
        "\n",
        "# Test examples\n",
        "print(\"\\n=== Test 1 ===\")\n",
        "predict_sentiment(\"This movie was absolutely fantastic. I loved every minute of it!\")\n",
        "\n",
        "print(\"\\n=== Test 2 ===\")\n",
        "predict_sentiment(\"Worst movie ever. Total waste of time and money.\")\n",
        "\n",
        "print(\"\\n=== Test 3 ===\")\n",
        "predict_sentiment(\"The film had good acting but the story was boring and predictable.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGXP8WvLIPx0",
        "outputId": "2313df41-e925-4707-a60e-3542f0260625"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test 1 ===\n",
            "Embedding batch 0 to 0...\n",
            "üìù Review:\n",
            "This movie was absolutely fantastic. I loved every minute of it!\n",
            "\n",
            "üéØ Prediction: Positive\n",
            "üìä Confidence: [3.8653612e-04 9.9961346e-01]\n",
            "\n",
            "=== Test 2 ===\n",
            "Embedding batch 0 to 0...\n",
            "üìù Review:\n",
            "Worst movie ever. Total waste of time and money.\n",
            "\n",
            "üéØ Prediction: Negative\n",
            "üìä Confidence: [9.9992335e-01 7.6668890e-05]\n",
            "\n",
            "=== Test 3 ===\n",
            "Embedding batch 0 to 0...\n",
            "üìù Review:\n",
            "The film had good acting but the story was boring and predictable.\n",
            "\n",
            "üéØ Prediction: Negative\n",
            "üìä Confidence: [0.9926853  0.00731467]\n"
          ]
        }
      ]
    }
  ]
}
