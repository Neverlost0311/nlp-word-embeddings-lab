{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsFJ8S6b/FVjrdUB05AMMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neverlost0311/nlp-word-embeddings-lab/blob/main/05-word-analogies/lab5_word_analogies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5: Word Analogies with Embeddings\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this lab, we will explore how **word embeddings capture relationships** between words using **vector arithmetic**.\n",
        "\n",
        "We will demonstrate analogies like:\n",
        "\n",
        "- king - man + woman ‚âà queen  \n",
        "- Paris - France + Germany ‚âà Berlin  \n",
        "- walking - walk + swim ‚âà swimming  \n",
        "\n",
        "This shows that embeddings encode **semantic relationships**, not just similarity.\n"
      ],
      "metadata": {
        "id": "9WxnOWBjFHlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 1: Install & Import Libraries\n",
        "# ================================\n",
        "\n",
        "!pip install -q google-genai numpy scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google import genai\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ Libraries installed and imported\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nZ40_2oFI1n",
        "outputId": "b7bcb38e-e866-425e-f8e4-97fead0783bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries installed and imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 2: Setup Gemini API Key\n",
        "# ================================\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "API_KEY = getpass(\"Enter your Gemini API Key: \")\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = API_KEY\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "print(\"‚úÖ Gemini client created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8JhgfKpFLZF",
        "outputId": "313e71b5-d32f-42d9-d67c-fcb8d0c9ee95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Gemini API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Gemini client created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 3: Embedding Helper\n",
        "# ================================\n",
        "\n",
        "MODEL_NAME = \"models/text-embedding-004\"\n",
        "\n",
        "def get_embedding(text):\n",
        "    result = client.models.embed_content(\n",
        "        model=MODEL_NAME,\n",
        "        contents=[text]\n",
        "    )\n",
        "    return np.array(result.embeddings[0].values)\n",
        "\n",
        "print(\"‚úÖ Embedding function ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY22LMK2FT8P",
        "outputId": "d2536d7b-ed73-4bda-8ca9-1171701dfcbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Embedding function ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 4: Analogy Solver\n",
        "# ================================\n",
        "\n",
        "def solve_analogy(a, b, c, candidates):\n",
        "    \"\"\"\n",
        "    Solves: a - b + c ‚âà ?\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç Solving: {a} - {b} + {c} = ?\")\n",
        "\n",
        "    ea = get_embedding(a)\n",
        "    eb = get_embedding(b)\n",
        "    ec = get_embedding(c)\n",
        "\n",
        "    target = ea - eb + ec\n",
        "\n",
        "    best_word = None\n",
        "    best_score = -1\n",
        "\n",
        "    for word in candidates:\n",
        "        ew = get_embedding(word)\n",
        "        score = cosine_similarity([target], [ew])[0][0]\n",
        "\n",
        "        print(f\"Similarity with {word}: {score:.4f}\")\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_word = word\n",
        "\n",
        "    print(f\"\\n‚úÖ Best match: {best_word}\")\n",
        "    return best_word\n"
      ],
      "metadata": {
        "id": "1a_af8QYFXqi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 5: Test 1 ‚Äî king - man + woman\n",
        "# ================================\n",
        "\n",
        "candidates = [\"queen\", \"princess\", \"man\", \"woman\", \"king\", \"prince\"]\n",
        "\n",
        "solve_analogy(\"king\", \"man\", \"woman\", candidates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "cCzHbprrFaxc",
        "outputId": "40e4d05f-cc73-4e71-a063-48df2a2c2b35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Solving: king - man + woman = ?\n",
            "Similarity with queen: 0.6000\n",
            "Similarity with princess: 0.5823\n",
            "Similarity with man: 0.0621\n",
            "Similarity with woman: 0.6003\n",
            "Similarity with king: 0.7232\n",
            "Similarity with prince: 0.4080\n",
            "\n",
            "‚úÖ Best match: king\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'king'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 6: Test 2 ‚Äî Paris - France + Germany\n",
        "# ================================\n",
        "\n",
        "candidates = [\"Berlin\", \"Munich\", \"Paris\", \"Rome\", \"Madrid\", \"Germany\"]\n",
        "\n",
        "solve_analogy(\"Paris\", \"France\", \"Germany\", candidates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "G8l32PyjFi91",
        "outputId": "2155dbab-b88c-44b9-c279-e5a0580e5e9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Solving: Paris - France + Germany = ?\n",
            "Similarity with Berlin: 0.7613\n",
            "Similarity with Munich: 0.6708\n",
            "Similarity with Paris: 0.6336\n",
            "Similarity with Rome: 0.4595\n",
            "Similarity with Madrid: 0.5197\n",
            "Similarity with Germany: 0.8125\n",
            "\n",
            "‚úÖ Best match: Germany\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Germany'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell 7: Test 3 ‚Äî walking - walk + swim\n",
        "# ================================\n",
        "\n",
        "candidates = [\"swimming\", \"swim\", \"walk\", \"running\", \"jumping\"]\n",
        "\n",
        "solve_analogy(\"walking\", \"walk\", \"swim\", candidates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "2q5z7zaGFnpe",
        "outputId": "67d4ddc6-cbff-4cc7-de6a-9a6b0f4b3965"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Solving: walking - walk + swim = ?\n",
            "Similarity with swimming: 0.9474\n",
            "Similarity with swim: 0.9527\n",
            "Similarity with walk: 0.4535\n",
            "Similarity with running: 0.5242\n",
            "Similarity with jumping: 0.5140\n",
            "\n",
            "‚úÖ Best match: swim\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'swim'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "We observed that:\n",
        "\n",
        "- Embeddings support **vector arithmetic**\n",
        "- Relationships like:\n",
        "  - gender (king ‚Üí queen)\n",
        "  - geography (Paris ‚Üí Berlin)\n",
        "  - verb tense (walk ‚Üí walking)\n",
        "  are encoded in vector space\n",
        "\n",
        "This proves that **modern embeddings capture semantic relationships**, not just similarity.\n"
      ],
      "metadata": {
        "id": "F-jdafbhFvHi"
      }
    }
  ]
}